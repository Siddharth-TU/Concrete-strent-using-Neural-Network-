{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Keras and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.layers.convolutional import Conv2D # to add convolutional layers\n",
    "from keras.layers.convolutional import MaxPooling2D # to add pooling layers\n",
    "from keras.layers import Flatten # to flatten data for fully connected layers\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download concrete data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
       "0            1040.0           676.0   28     79.99  \n",
       "1            1055.0           676.0   28     61.89  \n",
       "2             932.0           594.0  270     40.27  \n",
       "3             932.0           594.0  365     41.05  \n",
       "4             978.4           825.5  360     44.30  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_data = pd.read_csv('https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0101EN/labs/data/concrete_data.csv')\n",
    "concrete_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Build a baseline model (5 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_model(n_cols):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # One hidden layer of 10 nodes, and a ReLU activation function\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    # Use the adam optimizer and the mean squared error as the loss function.\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trail_and_test(concrete_data, modeldef, n_epochs=50):\n",
    "    # 1. Randomly split the data into a training and test sets by holding 30% of the data for testing\n",
    "    train_data, test_data = train_test_split(concrete_data, test_size=0.3)\n",
    "\n",
    "    ## Split data into predictors and target\n",
    "    predictors_train = train_data[train_data.columns[train_data.columns != 'Strength']] # all columns except Strength\n",
    "    target_train = train_data['Strength'] # Strength column\n",
    "\n",
    "    predictors_test = test_data[test_data.columns[test_data.columns != 'Strength']] # all columns except Strength\n",
    "    target_test = test_data['Strength'] # Strength column\n",
    "\n",
    "    n_cols = predictors_train.shape[1] # number of predictors\n",
    "\n",
    "    # 2. Train the model on the training data using 50 epochs.\n",
    "    model = modeldef(n_cols=n_cols)\n",
    "    model.fit(predictors_train, target_train, validation_split=0.3, epochs=n_epochs, verbose=0)\n",
    "\n",
    "    # 3. Evaluate the model on the test data and compute the mean squared error between the predicted concrete strength and the actual concrete strength.\n",
    "    # You can use the mean_squared_error function from Scikit-learn.\n",
    "    predictions = model.predict(predictors_test, batch_size=None, verbose=1, steps=None)\n",
    "    mse = mean_squared_error(target_test, predictions)\n",
    "    #model.evaluate(predictors_test, target_test, verbose=0)\n",
    "\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309/309 [==============================] - 0s 193us/step\n",
      "309/309 [==============================] - 0s 260us/step\n",
      "309/309 [==============================] - 0s 318us/step\n",
      "309/309 [==============================] - 0s 320us/step\n",
      "309/309 [==============================] - 0s 394us/step\n",
      "309/309 [==============================] - 0s 501us/step\n",
      "309/309 [==============================] - 0s 505us/step\n",
      "309/309 [==============================] - 0s 590us/step\n",
      "309/309 [==============================] - 0s 645us/step\n",
      "309/309 [==============================] - 0s 709us/step\n",
      "309/309 [==============================] - 0s 764us/step\n",
      "309/309 [==============================] - 0s 783us/step\n",
      "309/309 [==============================] - 0s 1ms/step\n",
      "309/309 [==============================] - 0s 912us/step\n",
      "309/309 [==============================] - 0s 1ms/step\n",
      "309/309 [==============================] - 0s 1ms/step\n",
      "309/309 [==============================] - 0s 1ms/step\n",
      "309/309 [==============================] - 0s 1ms/step\n",
      "309/309 [==============================] - 0s 1ms/step\n",
      "309/309 [==============================] - 0s 1ms/step\n",
      "309/309 [==============================] - 0s 1ms/step\n",
      "309/309 [==============================] - 0s 2ms/step\n",
      "309/309 [==============================] - 1s 2ms/step\n",
      "309/309 [==============================] - 1s 2ms/step\n",
      "309/309 [==============================] - 1s 2ms/step\n",
      "309/309 [==============================] - 1s 2ms/step\n",
      "309/309 [==============================] - 1s 2ms/step\n",
      "309/309 [==============================] - 1s 2ms/step\n",
      "309/309 [==============================] - 1s 2ms/step\n",
      "309/309 [==============================] - 1s 2ms/step\n",
      "309/309 [==============================] - 1s 3ms/step\n",
      "309/309 [==============================] - 1s 2ms/step\n",
      "309/309 [==============================] - 1s 3ms/step\n",
      "309/309 [==============================] - 1s 3ms/step\n",
      "309/309 [==============================] - 1s 3ms/step\n",
      "309/309 [==============================] - 1s 3ms/step\n",
      "309/309 [==============================] - 1s 3ms/step\n",
      "309/309 [==============================] - 1s 3ms/step\n",
      "309/309 [==============================] - 1s 3ms/step\n",
      "309/309 [==============================] - 1s 3ms/step\n",
      "309/309 [==============================] - 1s 3ms/step\n",
      "309/309 [==============================] - 1s 3ms/step\n",
      "309/309 [==============================] - 1s 4ms/step\n",
      "309/309 [==============================] - 1s 4ms/step\n",
      "309/309 [==============================] - 1s 4ms/step\n",
      "309/309 [==============================] - 1s 4ms/step\n",
      "309/309 [==============================] - 1s 4ms/step\n",
      "309/309 [==============================] - 1s 4ms/step\n",
      "309/309 [==============================] - 1s 4ms/step\n",
      "309/309 [==============================] - 1s 4ms/step\n",
      "Mean: 539.2714937496307, Stddev: 660.4743586716176\n"
     ]
    }
   ],
   "source": [
    "# 4. Repeat steps 1 - 3, 50 times, i.e., create a list of 50 mean squared errors.\n",
    "mses = np.array([trail_and_test(concrete_data, modeldef=regression_model, n_epochs=50) for i in range(50)])\n",
    "# 5. Report the mean and the standard deviation of the mean squared errors\n",
    "print('Mean: {mean}, Stddev: {std}'.format(mean=mses.mean(), std=mses.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Normalize the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_normalised(concrete_data, modeldef, n_epochs):\n",
    "    # 1. Randomly split the data into a training and test sets by holding 30% of the data for testing\n",
    "    train_data, test_data = train_test_split(concrete_data, test_size=0.3)\n",
    "\n",
    "    ## Split data into predictors and target\n",
    "    predictors_train = train_data[train_data.columns[train_data.columns != 'Strength']] # all columns except Strength\n",
    "    target_train = train_data['Strength'] # Strength column\n",
    "\n",
    "    predictors_test = test_data[test_data.columns[test_data.columns != 'Strength']] # all columns except Strength\n",
    "    target_test = test_data['Strength'] # Strength column\n",
    "\n",
    "    # normalise predictors\n",
    "    predictors_train_norm = (predictors_train - predictors_train.mean()) / predictors_train.std()\n",
    "    predictors_test_norm = (predictors_test - predictors_test.mean()) / predictors_test.std()\n",
    "\n",
    "    n_cols = predictors_train_norm.shape[1] # number of predictors\n",
    "\n",
    "    # 2. Train the model on the training data using 50 epochs.\n",
    "    model = modeldef(n_cols=n_cols)\n",
    "    # Train the model on the training data using 50 epochs.\n",
    "    model.fit(predictors_train_norm, target_train, validation_split=0.3, epochs=n_epochs, verbose=0)\n",
    "\n",
    "    # 3. Evaluate the model on the test data and compute the mean squared error between the predicted concrete strength and the actual concrete strength. You can use the mean_squared_error function from Scikit-learn.\n",
    "    predictions = model.predict(predictors_test_norm, batch_size=None, verbose=1, steps=None)\n",
    "    mse = mean_squared_error(target_test, predictions)\n",
    "    print(mse)\n",
    "    #model.evaluate(predictors_test, target_test, verbose=0)\n",
    "\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309/309 [==============================] - 1s 4ms/step\n",
      "895.8366768559019\n",
      "309/309 [==============================] - 1s 5ms/step\n",
      "538.8349123503775\n",
      "309/309 [==============================] - 1s 4ms/step\n",
      "537.6522596509329\n",
      "309/309 [==============================] - 1s 5ms/step\n",
      "718.2132841960835\n",
      "309/309 [==============================] - 2s 5ms/step\n",
      "554.2272068624947\n",
      "309/309 [==============================] - 1s 5ms/step\n",
      "688.2612701336302\n",
      "309/309 [==============================] - 1s 5ms/step\n",
      "630.2078953375573\n",
      "309/309 [==============================] - 2s 5ms/step\n",
      "570.0388945656377\n",
      "309/309 [==============================] - 2s 5ms/step\n",
      "553.0614280542312\n",
      "309/309 [==============================] - 2s 5ms/step\n",
      "573.9188361694559\n",
      "309/309 [==============================] - 2s 6ms/step\n",
      "515.2981959631069\n",
      "309/309 [==============================] - 2s 6ms/step\n",
      "613.4661391813387\n",
      "309/309 [==============================] - 2s 6ms/step\n",
      "974.4034190455617\n",
      "309/309 [==============================] - 2s 6ms/step\n",
      "616.3032867403359\n",
      "309/309 [==============================] - 2s 6ms/step\n",
      "760.9647654819323\n",
      "309/309 [==============================] - 2s 6ms/step\n",
      "617.7627110817731\n",
      "309/309 [==============================] - 2s 6ms/step\n",
      "865.4788951120621\n",
      "309/309 [==============================] - 2s 6ms/step\n",
      "702.5712501664436\n",
      "309/309 [==============================] - 2s 7ms/step\n",
      "806.1935364950012\n",
      "309/309 [==============================] - 2s 6ms/step\n",
      "644.466692149121\n",
      "309/309 [==============================] - 2s 7ms/step\n",
      "605.9526166150196\n",
      "309/309 [==============================] - 2s 7ms/step\n",
      "709.2213573595377\n",
      "309/309 [==============================] - 2s 7ms/step\n",
      "629.098663761657\n",
      "309/309 [==============================] - 2s 7ms/step\n",
      "660.1426338191311\n",
      "309/309 [==============================] - 2s 7ms/step\n",
      "488.9845426263882\n",
      "309/309 [==============================] - 2s 7ms/step\n",
      "686.2913867205162\n",
      "309/309 [==============================] - 2s 7ms/step\n",
      "730.6064014332522\n",
      "309/309 [==============================] - 2s 7ms/step\n",
      "591.6938573122541\n",
      "309/309 [==============================] - 2s 7ms/step\n",
      "732.3091724372127\n",
      "309/309 [==============================] - 2s 7ms/step\n",
      "609.7222085590635\n",
      "309/309 [==============================] - 2s 7ms/step\n",
      "549.360016934034\n",
      "309/309 [==============================] - 2s 8ms/step\n",
      "1016.3516083374506\n",
      "309/309 [==============================] - 2s 8ms/step\n",
      "616.5504204674895\n",
      "309/309 [==============================] - 3s 9ms/step\n",
      "596.9292485302745\n",
      "309/309 [==============================] - 3s 8ms/step\n",
      "549.556820153158\n",
      "309/309 [==============================] - 3s 8ms/step\n",
      "844.2119893611182\n",
      "309/309 [==============================] - 3s 9ms/step\n",
      "557.2660750708391\n",
      "309/309 [==============================] - 3s 8ms/step\n",
      "635.2520690051538\n",
      "309/309 [==============================] - 3s 9ms/step\n",
      "719.8172720522449\n",
      "309/309 [==============================] - 3s 9ms/step\n",
      "957.680689743131\n",
      "309/309 [==============================] - 3s 9ms/step\n",
      "622.9847286661791\n",
      "309/309 [==============================] - 3s 9ms/step\n",
      "1061.4911852101775\n",
      "309/309 [==============================] - 3s 9ms/step\n",
      "526.7092435305942\n",
      "309/309 [==============================] - 3s 10ms/step\n",
      "730.0483210206464\n",
      "309/309 [==============================] - 3s 9ms/step\n",
      "481.9919725872778\n",
      "309/309 [==============================] - 3s 9ms/step\n",
      "733.4981436994185\n",
      "309/309 [==============================] - 3s 10ms/step\n",
      "494.7805452331136\n",
      "309/309 [==============================] - 3s 9ms/step\n",
      "983.1717735984989\n",
      "309/309 [==============================] - 3s 10ms/step\n",
      "746.6283677945105\n",
      "309/309 [==============================] - 3s 10ms/step\n",
      "618.009658677717\n",
      "Mean: 677.2694909182007, Stddev: 143.2904362488982\n"
     ]
    }
   ],
   "source": [
    "mses = np.array([train_and_test_normalised(concrete_data, modeldef=regression_model, n_epochs=50) for i in range(50)])\n",
    "print('Mean: {mean}, Stddev: {std}'.format(mean=mses.mean(), std=mses.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does the mean of the mean squared errors compare to that from Step A?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step A(Baseline Model)\n",
    "    - mean: 539.2714937496307\n",
    "    - std: 660.4743586716176\n",
    "#### Step B(Normalised feature):\n",
    "    - mean: 677.2694909182007\n",
    "    - std: 143.2904362488982"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result\n",
    "The mean of the MSE of B is a bit worse than A, but the standard deviation of B is much less than A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Increate the number of epochs (5 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309/309 [==============================] - 3s 10ms/step\n",
      "223.85398452039425\n",
      "309/309 [==============================] - 3s 10ms/step\n",
      "517.0112666824906\n",
      "309/309 [==============================] - 3s 10ms/step\n",
      "273.9694154504999\n",
      "309/309 [==============================] - 3s 10ms/step\n",
      "192.82145966930696\n",
      "309/309 [==============================] - 3s 10ms/step\n",
      "210.51179032381697\n",
      "309/309 [==============================] - 3s 10ms/step\n",
      "203.76187841575143\n",
      "309/309 [==============================] - 4s 12ms/step\n",
      "275.7925823897395\n",
      "309/309 [==============================] - 3s 11ms/step\n",
      "248.05057504896035\n",
      "309/309 [==============================] - 3s 11ms/step\n",
      "197.05622773425705\n",
      "309/309 [==============================] - 3s 11ms/step\n",
      "406.27738068568686\n",
      "309/309 [==============================] - 3s 11ms/step\n",
      "225.62654009719517\n",
      "309/309 [==============================] - 3s 11ms/step\n",
      "266.88727204063923\n",
      "309/309 [==============================] - 3s 11ms/step\n",
      "217.397101004695\n",
      "309/309 [==============================] - 4s 12ms/step\n",
      "196.07659873182126\n",
      "309/309 [==============================] - 4s 12ms/step\n",
      "225.6887580436478\n",
      "309/309 [==============================] - 4s 12ms/step\n",
      "219.66798500869552\n",
      "309/309 [==============================] - 4s 12ms/step\n",
      "208.0678900311614\n",
      "309/309 [==============================] - 4s 12ms/step\n",
      "164.07400523585625\n",
      "309/309 [==============================] - 4s 12ms/step\n",
      "185.30048518729134\n",
      "309/309 [==============================] - 4s 12ms/step\n",
      "174.86220887238449\n",
      "309/309 [==============================] - 4s 12ms/step\n",
      "201.65090344579735\n",
      "309/309 [==============================] - 4s 12ms/step\n",
      "255.85863949522448\n",
      "309/309 [==============================] - 4s 13ms/step\n",
      "216.93556424267325\n",
      "309/309 [==============================] - 4s 13ms/step\n",
      "231.12417280880118\n",
      "309/309 [==============================] - 4s 13ms/step\n",
      "218.68054735479228\n",
      "309/309 [==============================] - 4s 13ms/step\n",
      "177.3554266554538\n",
      "309/309 [==============================] - 4s 13ms/step\n",
      "236.39954624102558\n",
      "309/309 [==============================] - 4s 13ms/step\n",
      "171.72589147405694\n",
      "309/309 [==============================] - 4s 13ms/step\n",
      "282.82231217965216\n",
      "309/309 [==============================] - 4s 13ms/step\n",
      "243.52100874970293\n",
      "309/309 [==============================] - 4s 13ms/step\n",
      "234.570346607437\n",
      "309/309 [==============================] - 4s 14ms/step\n",
      "237.2361090737491\n",
      "309/309 [==============================] - 4s 14ms/step\n",
      "201.55175548851577\n",
      "309/309 [==============================] - 4s 14ms/step\n",
      "241.4706696683715\n",
      "309/309 [==============================] - 4s 14ms/step\n",
      "245.4376122436043\n",
      "309/309 [==============================] - 4s 14ms/step\n",
      "230.38018871474776\n",
      "309/309 [==============================] - 4s 14ms/step\n",
      "251.01166881550506\n",
      "309/309 [==============================] - 5s 15ms/step\n",
      "186.15597688970462\n",
      "309/309 [==============================] - 4s 14ms/step\n",
      "224.73719531832234\n",
      "309/309 [==============================] - 5s 15ms/step\n",
      "179.49625466998492\n",
      "309/309 [==============================] - 5s 15ms/step\n",
      "174.67780751457244\n",
      "309/309 [==============================] - 5s 15ms/step\n",
      "192.17686078065307\n",
      "309/309 [==============================] - 5s 15ms/step\n",
      "195.76743850888556\n",
      "309/309 [==============================] - 5s 15ms/step\n",
      "259.42776889111997\n",
      "309/309 [==============================] - 5s 15ms/step\n",
      "182.9980898029085\n",
      "309/309 [==============================] - 5s 15ms/step\n",
      "258.09291555575516\n",
      "309/309 [==============================] - 5s 15ms/step\n",
      "199.05006328710505\n",
      "309/309 [==============================] - 5s 15ms/step\n",
      "270.42549994293506\n",
      "Mean: 228.31948220629343, Stddev: 57.71126727954665\n"
     ]
    }
   ],
   "source": [
    "# Repeat Part B but use 100 epochs this time for training.\n",
    "mses = np.array([train_and_test_normalised(concrete_data, modeldef=regression_model, n_epochs=100) for i in range(50)])\n",
    "print('Mean: {mean}, Stddev: {std}'.format(mean=mses.mean(), std=mses.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does the mean of the mean squared errors compare to that from Step B?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step B(Normalised feature):\n",
    "    - mean: 670.1222133203134\n",
    "    - std: 139.2909256592924\n",
    "#### Step C(Train w/ double epoch):\n",
    "    - mean: 228.31948220629343\n",
    "    - std: 57.71126727954665"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result\n",
    "Both of the mean and the standard deviation of C is much better than B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. Increase the number of hidden layers (5 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Three hidden layers, each of 10 nodes and ReLU activation function.\n",
    "def regression_model_2(n_cols):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # One hidden layer of 10 nodes, and a ReLU activation function\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    # Use the adam optimizer and the mean squared error as the loss function.\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309/309 [==============================] - 5s 16ms/step\n",
      "168.76705515794248\n",
      "309/309 [==============================] - 5s 16ms/step\n",
      "152.37805802615483\n",
      "309/309 [==============================] - 5s 16ms/step\n",
      "138.0862583685326\n",
      "309/309 [==============================] - 5s 16ms/step\n",
      "157.90373219208885\n",
      "309/309 [==============================] - 5s 17ms/step\n",
      "161.08597016054026\n",
      "309/309 [==============================] - 5s 17ms/step\n",
      "150.01149373859212\n",
      "309/309 [==============================] - 5s 17ms/step\n",
      "162.11951288517483\n",
      "309/309 [==============================] - 5s 17ms/step\n",
      "139.1288333203001\n",
      "309/309 [==============================] - 5s 18ms/step\n",
      "134.91886798127697\n",
      "309/309 [==============================] - 5s 17ms/step\n",
      "152.15621183209117\n",
      "309/309 [==============================] - 6s 18ms/step\n",
      "150.97036108938943\n",
      "309/309 [==============================] - 5s 18ms/step\n",
      "140.8121730021355\n",
      "309/309 [==============================] - 6s 19ms/step\n",
      "145.9784960636683\n",
      "309/309 [==============================] - 6s 18ms/step\n",
      "162.02162292561107\n",
      "309/309 [==============================] - 6s 18ms/step\n",
      "153.05217317600633\n",
      "309/309 [==============================] - 6s 19ms/step\n",
      "134.73216695145402\n",
      "309/309 [==============================] - 6s 19ms/step\n",
      "156.16500996431918\n",
      "309/309 [==============================] - 6s 19ms/step\n",
      "168.383752710478\n",
      "309/309 [==============================] - 6s 19ms/step\n",
      "148.44856691489062\n",
      "309/309 [==============================] - 6s 19ms/step\n",
      "136.6344734060594\n",
      "309/309 [==============================] - 6s 20ms/step\n",
      "109.80177418286205\n",
      "309/309 [==============================] - 6s 21ms/step\n",
      "153.11641534341095\n",
      "309/309 [==============================] - 6s 20ms/step\n",
      "154.85225235898724\n",
      "309/309 [==============================] - 6s 20ms/step\n",
      "171.5508089630442\n",
      "309/309 [==============================] - 6s 21ms/step\n",
      "130.81446250241856\n",
      "309/309 [==============================] - 6s 21ms/step\n",
      "160.29521997008908\n",
      "309/309 [==============================] - 6s 21ms/step\n",
      "176.73897479257823\n",
      "309/309 [==============================] - 7s 21ms/step\n",
      "170.04782895007418\n",
      "309/309 [==============================] - 7s 22ms/step\n",
      "152.3746076926652\n",
      "309/309 [==============================] - 7s 21ms/step\n",
      "144.72297767681104\n",
      "309/309 [==============================] - 7s 22ms/step\n",
      "156.49220426032284\n",
      "309/309 [==============================] - 7s 22ms/step\n",
      "155.04916180653356\n",
      "309/309 [==============================] - 7s 22ms/step\n",
      "158.86459121007186\n",
      "309/309 [==============================] - 7s 22ms/step\n",
      "132.2005601721169\n",
      "309/309 [==============================] - 7s 23ms/step\n",
      "160.47720303982177\n",
      "309/309 [==============================] - 7s 23ms/step\n",
      "161.19217174096693\n",
      "309/309 [==============================] - 7s 23ms/step\n",
      "150.59410384474592\n",
      "309/309 [==============================] - 7s 23ms/step\n",
      "143.87387494483778\n",
      "309/309 [==============================] - 7s 23ms/step\n",
      "145.65354379258113\n",
      "309/309 [==============================] - 7s 24ms/step\n",
      "100.89176283856784\n",
      "309/309 [==============================] - 7s 24ms/step\n",
      "145.82646933290005\n",
      "309/309 [==============================] - 7s 24ms/step\n",
      "143.6245864026016\n",
      "309/309 [==============================] - 7s 24ms/step\n",
      "146.15976388336637\n",
      "309/309 [==============================] - 7s 24ms/step\n",
      "159.81794577219415\n",
      "309/309 [==============================] - 8s 25ms/step\n",
      "168.28040202590807\n",
      "309/309 [==============================] - 8s 25ms/step\n",
      "138.4935780092432\n",
      "309/309 [==============================] - 8s 25ms/step\n",
      "155.87470391924612\n",
      "309/309 [==============================] - 8s 26ms/step\n",
      "153.28323843241031\n",
      "309/309 [==============================] - 8s 25ms/step\n",
      "140.29935291001897\n",
      "309/309 [==============================] - 8s 25ms/step\n",
      "152.9753433930656\n",
      "309/309 [==============================] - 8s 26ms/step\n",
      "143.63661852289457\n",
      "309/309 [==============================] - 8s 26ms/step\n",
      "140.55413972206102\n",
      "309/309 [==============================] - 8s 27ms/step\n",
      "147.37991709952468\n",
      "309/309 [==============================] - 8s 27ms/step\n",
      "148.89061394105786\n",
      "309/309 [==============================] - 8s 26ms/step\n",
      "138.0190635763946\n",
      "309/309 [==============================] - 8s 27ms/step\n",
      "172.51868645955238\n",
      "309/309 [==============================] - 9s 28ms/step\n",
      "143.71721885997928\n",
      "309/309 [==============================] - 9s 30ms/step\n",
      "137.54101104572956\n",
      "309/309 [==============================] - 9s 28ms/step\n",
      "121.47788474443638\n",
      "309/309 [==============================] - 8s 27ms/step\n",
      "139.0639651399945\n",
      "309/309 [==============================] - 9s 28ms/step\n",
      "137.9504804765837\n",
      "309/309 [==============================] - 10s 31ms/step\n",
      "175.06820466225344\n",
      "309/309 [==============================] - 9s 28ms/step\n",
      "157.30131476323228\n",
      "309/309 [==============================] - 9s 29ms/step\n",
      "153.90716523838918\n",
      "309/309 [==============================] - 9s 28ms/step\n",
      "160.95771501452413\n",
      "309/309 [==============================] - 9s 28ms/step\n",
      "111.0631318048073\n",
      "309/309 [==============================] - 10s 32ms/step\n",
      "136.58210455186787\n",
      "309/309 [==============================] - 9s 29ms/step\n",
      "157.95454388965726\n",
      "309/309 [==============================] - 9s 30ms/step\n",
      "143.14817101997318\n",
      "309/309 [==============================] - 9s 30ms/step\n",
      "134.93983607796406\n",
      "309/309 [==============================] - 9s 30ms/step\n",
      "160.49658506271476\n",
      "309/309 [==============================] - 10s 33ms/step\n",
      "174.66073042900152\n",
      "309/309 [==============================] - 10s 31ms/step\n",
      "135.5063009168732\n",
      "309/309 [==============================] - 10s 31ms/step\n",
      "150.36312869854038\n",
      "309/309 [==============================] - 9s 31ms/step\n",
      "175.8985336274974\n",
      "309/309 [==============================] - 10s 31ms/step\n",
      "139.36868964743746\n",
      "309/309 [==============================] - 10s 31ms/step\n",
      "159.78998934751453\n",
      "309/309 [==============================] - 11s 35ms/step\n",
      "157.8787471923448\n",
      "309/309 [==============================] - 10s 32ms/step\n",
      "136.38345909178912\n",
      "309/309 [==============================] - 10s 31ms/step\n",
      "147.25612676560613\n",
      "309/309 [==============================] - 10s 32ms/step\n",
      "127.37179947853413\n",
      "309/309 [==============================] - 10s 32ms/step\n",
      "173.971447952696\n",
      "309/309 [==============================] - 10s 33ms/step\n",
      "135.40502110763165\n",
      "309/309 [==============================] - 10s 33ms/step\n",
      "168.2479285198929\n",
      "309/309 [==============================] - 10s 33ms/step\n",
      "130.52254293621135\n",
      "309/309 [==============================] - 10s 33ms/step\n",
      "166.7572807069245\n",
      "309/309 [==============================] - 10s 33ms/step\n",
      "129.51027304909792\n",
      "309/309 [==============================] - 10s 34ms/step\n",
      "144.96870219988548\n",
      "309/309 [==============================] - 11s 34ms/step\n",
      "156.1786851147796\n",
      "309/309 [==============================] - 10s 34ms/step\n",
      "155.55111865304804\n",
      "309/309 [==============================] - 11s 35ms/step\n",
      "144.99745206962538\n",
      "309/309 [==============================] - 11s 34ms/step\n",
      "146.74790259788617\n",
      "309/309 [==============================] - 11s 35ms/step\n",
      "152.96318112311144\n",
      "309/309 [==============================] - 11s 36ms/step\n",
      "128.88080172975393\n",
      "309/309 [==============================] - 11s 37ms/step\n",
      "164.68695539130673\n",
      "309/309 [==============================] - 11s 36ms/step\n",
      "156.56357344101403\n",
      "309/309 [==============================] - 11s 36ms/step\n",
      "145.26732489280298\n",
      "309/309 [==============================] - 11s 36ms/step\n",
      "138.75811124303547\n",
      "Mean: 148.9130410346697, Stddev: 14.453772413834463\n"
     ]
    }
   ],
   "source": [
    "mses = np.array([train_and_test_normalised(concrete_data, modeldef=regression_model_2, n_epochs=50) for i in range(100)])\n",
    "print('Mean: {mean}, Stddev: {std}'.format(mean=mses.mean(), std=mses.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does the mean of the mean squared errors compare to that from Step B?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step B(Normalised feature):\n",
    "    - mean: 670.1222133203134\n",
    "    - std: 139.2909256592924\n",
    "#### Step D(Enhanced hidden layer):\n",
    "    - mean: 148.9130410346697\n",
    "    - std: 14.453772413834463"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reuslt\n",
    "Both of the mean and the standart deviation of MSE of D is significant better than B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
